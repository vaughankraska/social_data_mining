{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasky/dev/social_data_mining/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /home/krasky/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/krasky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/krasky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from text_mining.utils import annotate_texts, analyze_with_vader, krippendorff_analysis, train_classifier, preprocess_tweets, analyze_with_transformer\n",
    "from text_mining.data import load_excel_annotations, load_sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len = 5000, test len = 1000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 189 entries, 0 to 80\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      189 non-null    int64  \n",
      " 1   CODE    189 non-null    float64\n",
      " 2   TEXT    189 non-null    object \n",
      " 3   coder   189 non-null    int64  \n",
      " 4   train   189 non-null    bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(1)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = load_excel_annotations(\"../../../../data/train.xlsx\")\n",
    "df_train[\"train\"] = True\n",
    "df_test = load_excel_annotations(\"../../../../data/test.xlsx\")\n",
    "df_test[\"train\"] = False\n",
    "df = pd.concat([df_train, df_test])\n",
    "print(f\"train len = {len(df_train)}, test len = {len(df_test)}\")\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  **Own Dictionary**\n",
    "   - Use a custom dictionary for tweet annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CODE</th>\n",
       "      <th>coder</th>\n",
       "      <th>dict_sentiment</th>\n",
       "      <th>dict_sentiment_rounded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.890000e+02</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.737459e+17</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.112875</td>\n",
       "      <td>0.116402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.797108e+15</td>\n",
       "      <td>0.755519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624771</td>\n",
       "      <td>0.607748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.721652e+17</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.721886e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.722204e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.758148e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.758268e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID        CODE  coder  dict_sentiment  dict_sentiment_rounded\n",
       "count  1.890000e+02  189.000000  189.0      189.000000              189.000000\n",
       "mean   6.737459e+17    0.248677    1.0        0.112875                0.116402\n",
       "std    1.797108e+15    0.755519    0.0        0.624771                0.607748\n",
       "min    6.721652e+17   -1.000000    1.0       -1.000000               -1.000000\n",
       "25%    6.721886e+17    0.000000    1.0        0.000000                0.000000\n",
       "50%    6.722204e+17    0.000000    1.0        0.000000                0.000000\n",
       "75%    6.758148e+17    1.000000    1.0        0.500000                0.000000\n",
       "max    6.758268e+17    1.000000    1.0        1.000000                1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = annotate_texts(\n",
    "    df[\"TEXT\"].tolist(),\n",
    "    sentiment_dict_path=\"../../../../data/COPSSentimentDict.csv\"\n",
    "    )\n",
    "df[\"dict_sentiment\"] = annotations\n",
    "df[\"dict_sentiment_rounded\"] = [round(annotation) for annotation in annotations]\n",
    "# print(df[\"dict_sentiment_rounded\"].unique())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's Alpha: 0.1194\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'our dict': 31.75% agreement\n",
      "\n",
      "our dict comparison with other methods:\n",
      "  'our dict' vs. 'human': 31.75% agreement\n",
      "\n",
      " -- ROUNDED\n",
      "Krippendorff's Alpha: 0.0907\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'our dict rounded': 38.62% agreement\n",
      "\n",
      "our dict rounded comparison with other methods:\n",
      "  'our dict rounded' vs. 'human': 38.62% agreement\n"
     ]
    }
   ],
   "source": [
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"dict_sentiment\"]].to_numpy(),\n",
    "    method_names=[\"human\", \"our dict\"]\n",
    ")\n",
    "print(\"\\n -- ROUNDED\")\n",
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"dict_sentiment_rounded\"]].to_numpy(),\n",
    "    method_names=[\"human\", \"our dict rounded\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2: VADER**\n",
    "   - Employ VADER for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_sentiment</th>\n",
       "      <th>v_sentiment_rounded</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0772</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v_sentiment  v_sentiment_rounded  CODE\n",
       "47       0.0772                    0   1.0\n",
       "53       0.0000                    0  -1.0\n",
       "86       0.0000                    0   0.0\n",
       "77      -0.4404                    0  -1.0\n",
       "31       0.0000                    0   1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_annotations = analyze_with_vader(df[\"TEXT\"].tolist())\n",
    "df[\"v_sentiment\"] = v_annotations\n",
    "df[\"v_sentiment_rounded\"] = [round(a) for a in v_annotations]\n",
    "df[[\"v_sentiment\", \"v_sentiment_rounded\", \"CODE\"]].sample(10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's Alpha: 0.3590\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'vader': 20.63% agreement\n",
      "\n",
      "vader comparison with other methods:\n",
      "  'vader' vs. 'human': 20.63% agreement\n",
      "\n",
      "---ROUNDED---\n",
      "Krippendorff's Alpha: 0.3303\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'vader rounded': 53.44% agreement\n",
      "\n",
      "vader rounded comparison with other methods:\n",
      "  'vader rounded' vs. 'human': 53.44% agreement\n"
     ]
    }
   ],
   "source": [
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"v_sentiment\"]].to_numpy(),\n",
    "    method_names=[\"human\", \"vader\"]\n",
    ")\n",
    "print(\"\\n---ROUNDED---\")\n",
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"v_sentiment_rounded\"]].to_numpy(),\n",
    "    method_names=[\"human\", \"vader rounded\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: Machine Learning\n",
    "   - Train a classifier (**Naive Bayes**) using bag-of-words features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Rep:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         8\n",
      "         0.0       0.44      0.70      0.54        10\n",
      "         1.0       0.77      0.85      0.81        20\n",
      "\n",
      "    accuracy                           0.63        38\n",
      "   macro avg       0.40      0.52      0.45        38\n",
      "weighted avg       0.52      0.63      0.57        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krasky/dev/social_data_mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/krasky/dev/social_data_mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/krasky/dev/social_data_mining/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>ml_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CODE  ml_sentiment\n",
       "61  -1.0          -1.0\n",
       "64   1.0           1.0\n",
       "93   1.0           1.0\n",
       "1    0.0           0.0\n",
       "5    0.0           0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer, vectorizer = train_classifier(df[\"TEXT\"].tolist(), labels=df[\"CODE\"])\n",
    "ml_annotations = classifer.predict(vectorizer.transform(preprocess_tweets(df[\"TEXT\"])))\n",
    "df[\"ml_sentiment\"] = ml_annotations\n",
    "df[[\"CODE\", \"ml_sentiment\"]].sample(10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's Alpha: 0.9084\n",
      "The methods show strong agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "Human comparison with other methods:\n",
      "  'Human' vs. 'ML': 92.59% agreement\n",
      "\n",
      "ML comparison with other methods:\n",
      "  'ML' vs. 'Human': 92.59% agreement\n"
     ]
    }
   ],
   "source": [
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"ml_sentiment\"]].to_numpy(),\n",
    "    method_names=[\"Human\", \"ML\"]\n",
    ") # NOTE duh the methods show strong agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4: Transformer Model\n",
    "   - Apply a fine-tuned transformer model for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>llm_sentiment</th>\n",
       "      <th>llm_sentiment_rounded</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.999503</td>\n",
       "      <td>-1</td>\n",
       "      <td>mashable: \"All of us had to solve it together,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697897</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri 4th Dec. Indonesian school children to sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.984622</td>\n",
       "      <td>-1</td>\n",
       "      <td>The Climate Change Issue Global Leaders Aren‚Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921732</td>\n",
       "      <td>1</td>\n",
       "      <td>President Obama &amp;amp; Bill Gates announce hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.984413</td>\n",
       "      <td>-1</td>\n",
       "      <td>Editorial: @Stanford and others should join @U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.991314</td>\n",
       "      <td>-1</td>\n",
       "      <td>RT @IOM_news: Reference to #migration in lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.996951</td>\n",
       "      <td>-1</td>\n",
       "      <td>When you mean to write fossil fuel extraction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.964681</td>\n",
       "      <td>-1</td>\n",
       "      <td>@BishopMarc (Episcopal Dioc. California) to le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.987544</td>\n",
       "      <td>-1</td>\n",
       "      <td>Germany and the Netherlands Tackle the Risk of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.984917</td>\n",
       "      <td>-1</td>\n",
       "      <td>Hold thy tongue ¬†:¬†Times Argus Online Great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CODE  llm_sentiment  llm_sentiment_rounded  \\\n",
       "67   0.0      -0.999503                     -1   \n",
       "18   0.0       0.697897                      1   \n",
       "20  -1.0      -0.984622                     -1   \n",
       "13   1.0       0.921732                      1   \n",
       "47   0.0      -0.984413                     -1   \n",
       "90   1.0      -0.991314                     -1   \n",
       "17  -1.0      -0.996951                     -1   \n",
       "26   1.0      -0.964681                     -1   \n",
       "41   1.0      -0.987544                     -1   \n",
       "42   1.0      -0.984917                     -1   \n",
       "\n",
       "                                                 TEXT  \n",
       "67  mashable: \"All of us had to solve it together,...  \n",
       "18  Fri 4th Dec. Indonesian school children to sen...  \n",
       "20  The Climate Change Issue Global Leaders Aren‚Ä...  \n",
       "13  President Obama &amp; Bill Gates announce hist...  \n",
       "47  Editorial: @Stanford and others should join @U...  \n",
       "90  RT @IOM_news: Reference to #migration in lates...  \n",
       "17  When you mean to write fossil fuel extraction ...  \n",
       "26  @BishopMarc (Episcopal Dioc. California) to le...  \n",
       "41  Germany and the Netherlands Tackle the Risk of...  \n",
       "42  Hold thy tongue ¬†:¬†Times Argus Online Great ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_annotations = analyze_with_transformer(df[\"TEXT\"].tolist())\n",
    "df[\"llm_sentiment\"] = llm_annotations\n",
    "df[\"llm_sentiment_rounded\"] = [round(s) for s in llm_annotations]\n",
    "df[[\"CODE\", \"llm_sentiment\", \"llm_sentiment_rounded\", \"TEXT\"]].sample(10)\n",
    "# info: distilbert/distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's Alpha: 0.1666\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'llm sentiment': 0.00% agreement\n",
      "\n",
      "llm sentiment comparison with other methods:\n",
      "  'llm sentiment' vs. 'human': 0.00% agreement\n",
      "\n",
      "---ROUNDED---\n",
      "Krippendorff's Alpha: 0.0401\n",
      "The methods show poor agreement.\n",
      "\n",
      "Method-wise Agreement Summary:\n",
      "\n",
      "human comparison with other methods:\n",
      "  'human' vs. 'llm rounded': 34.39% agreement\n",
      "\n",
      "llm rounded comparison with other methods:\n",
      "  'llm rounded' vs. 'human': 34.39% agreement\n"
     ]
    }
   ],
   "source": [
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"llm_sentiment\"]],\n",
    "    method_names=[\"human\", \"llm sentiment\"]\n",
    ")\n",
    "print(\"\\n---ROUNDED---\")\n",
    "krippendorff_analysis(\n",
    "    df[[\"CODE\", \"llm_sentiment_rounded\"]],\n",
    "    method_names=[\"human\", \"llm rounded\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kripp walk\n",
    "temp = [\n",
    "    [1, 1],  # Tweet 1: All methods agree on 'positive'\n",
    "    [0, 0],  # Tweet 2: All methods agree on 'neutral'\n",
    "    [-1, -1],  # Tweet 3: All methods agree on 'negative'\n",
    "    [1, 1],  # Tweet 4: All methods agree on 'positive'\n",
    "    [0, 0],  # Tweet 5: All methods agree on 'neutral'\n",
    "]\n",
    "krippendorff_analysis(temp, method_names=[f\"{i}\" for i in range(len(temp[0]))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
